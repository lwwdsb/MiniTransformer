# MiniTransformer
This project is a from-scratch implementation of a mini version of the Transformer model using PyTorch, designed to help understand the core mechanisms behind modern sequence-to-sequence models such as BERT, GPT, and T5.This project was built as a hands-on exploration of deep learning for NLP â€” lightweight, educational, and fully readable.
